---
title: "A Call to Protect Open-Source AI in Europe"
author: "LAION.ai"
date: "April 28, 2023"
previewImg: "/images/blog/laion-black.png"
---

**An Open Letter to the European Parliament: Protecting Open-Source AI for a Safe, Secure, and Sovereign Digital Future**

LAION, alongside prominent research institutions and developers, has penned an open letter to the European Parliament to express concerns about the draft AI Act's potential impact on open-source research and development (R&D) in artificial intelligence (AI). The letter highlights the importance of open-source R&D for ensuring the safety, security, and competitiveness of AI in Europe and warns against the consequences of stifling such innovation.

## The Importance of Open-Source AI

The letter outlines three main reasons why open-source AI is worth protecting:

1. **Safety through transparency:** Open-source AI promotes safety by enabling researchers and authorities to audit model performance, identify risks, and establish mitigations or countermeasures.
2. **Competition:** Open-source AI allows small to medium enterprises to build on existing models and drive productivity, rather than relying on a few large firms for essential technology.
3. **Security:** Public and private organizations can adapt open-source models for specialized applications without sharing sensitive data with proprietary firms.

## Concerns with the Draft AI Act

The draft AI Act may introduce new requirements for foundation models, which could negatively impact open-source R&D in AI. The letter argues that "one size fits all" rules will stifle open-source R&D and could:

- Entrench proprietary gatekeepers, often large firms, to the detriment of open-source researchers and developers
- Limit academic freedom and prevent the European research community from studying models of public significance
- Reduce competition between model providers and drive investment in AI overseas

## Recommendations for the European Parliament

The open letter makes three key recommendations:

1. **Ensure open-source R&D can comply with the AI Act:** The Act should promote open-source R&D and recognize the distinctions between closed-source AI models offered as a service and AI models released as open-source code. Where appropriate, the Act should exempt open-source models from regulations intended for closed-source models.
2. **Impose requirements proportional to risk:** The Act should impose rules for foundation models that are proportional to their actual risk. A "one size fits all" framework could make it impossible to field low-risk and open-source models in Europe.
3. **Establish public research facilities for compute resources:** The EU should establish large-scale supercomputing facilities for AI research, enabling the European research community to study open-source foundation models under controlled conditions with public oversight.

## The Future of AI in Europe

The letter concludes with a call to action for the European Parliament to consider the points raised and foster a legislative environment that supports open-source R&D. This approach will promote safety through transparency, drive innovation and competition, and accelerate the development of a sovereign AI capability in Europe.

With numerous esteemed supporters, including the European Laboratory for Learning and Intelligent Systems (ELLIS), the Pan-European AI Network of Excellence, and the German AI Association (KI-Bundesverband), the letter serves as a powerful reminder of the importance of protecting open-source AI for the future of Europe.